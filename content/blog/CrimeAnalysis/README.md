---
title: Crime rate analysis for the City of Virginia Beach.
date: "2019-10-24T22:00:19+00:00"
layout: post
draft: false
path: "/posts/CrimeAnalysis/"
category: "Data Mining and EDA"
tags:
  - "Python-Pandas"
  - "Open Data"
  - "Virginia Beach, Virginia"
description: "Data fetched from public datasets are messy."
---

This post takes inspiration from the Kaggle's challenge of [Crimes in Boston](https://www.kaggle.com/AnalyzeBoston/crimes-in-boston/kernels), there are over 100 kernels and lot of amazing work has been already done. I wanted to do something tad bit different. I wanted to get data from a public database, in order to start exploring the messyness of real data. Everyone and I mean everyone that works with Data has heard this at some point or the other, "80% of data analysis is spent on the cleaning and preparing data". It is by no means a one step process, one will come back to this step over and over again.

While working on this mini-project I talk about

1. Lo-Fi/Lofi or Low Fidelity prototyping.
2. Data preprocessing.
3. Geopandas


<div style="text-align: center;"><embed src="https://crimedataanalysisvirginiabeach.netlify.com/" style="width:900px; height: 700px;"></div>


The site is deployed on Netlify, click [here](https://crimedataanalysisvirginiabeach.netlify.com/).